![](https://www.confluent.io/wp-content/uploads/streaming_platform_rev.png)

# Kafka

Kafka 它本质上是一个消息系统，它提供了常用的消息系统的功能集，但是它的设计更加独特，原本开发自 LinkedIn，用作 LinkedIn 的活动流(Activity Stream)和运营数据处理管道(Pipeline)的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。

![](http://images0.cnblogs.com/blog2015/666745/201505/261159103182564.png)

首先，Kafka 可以应用于消息系统，比如，当下较为热门的消息推送，这些消息推送系统的消息源，可以使用 Kafka 作为系统的核心组建来完成消息的生产 和消息的消费。然后是网站的行迹，我们可以将企业的 Portal，用户的操作记录等信息发送到 Kafka 中，按照实际业务需求，可以进行实时监控，或者做离线处理等。最后，一个是日志收集，类似于 Flume 套件这样的日志收集系统，但 Kafka 的设计架构采用 push/pull，适合异构集群，Kafka 可以批量提交消息，对 Producer 来说，在性能方面基本上是无消耗的，而在 Consumer 端中，我们可以使用 HDFS 这类的分布式文件存储系统进行存储。

# 特性

由于 Kafka 本身是存储计算耦合的架构，使得数据不均衡的问题经常凸显，集群扩容、故障恢复也变得异常麻烦，给运维工作带来不少痛苦；同时，由于 Consumer 的 Rebalance 算法每次都是全部重新计算，使得业务的消费体验也不是很好；
作者批注：存储计算耦合的架构在扩容和故障转移时都需要进行数据搬迁；故障恢复时一般要经历复杂的算法先选举 Leader，且提供服务前要先保证各副本数据是一致的。

# 组件

Kafka 是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：

- 以时间复杂度为 O(1)的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
- 支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out：支持在线水平扩展。

关键概念

| Concepts    | Function                                                                                                                                                                                                                                                                                                                                    |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Topic       | 用于划分 Message 的逻辑概念，一个 Topic 可以分布在多个 Broker 上                                                                                                                                                                                                                                                                            |
| Partition   | 是 Kafka 中横向扩展和一切并行化的基础，每个 Topic 都至少被切分为 1 个 Partition，                                                                                                                                                                                                                                                           |
| Offset      | 消息在 Partition 中的编号，编号顺序不跨 Partition(在 Partition 内有序)，                                                                                                                                                                                                                                                                    |
| Consumer    | 用于从 Broker 中取出/消费 Message，                                                                                                                                                                                                                                                                                                         |
| Producer    | 用于往 Broker 中发送/生产 Message，                                                                                                                                                                                                                                                                                                         |
| Replication | Kafka 支持以 Partition 为单位对 Message 进行冗余备份，每个 Partition 都可以配置至少 1 个 Replication(当仅 1 个 Replication 时即仅该 Partition 本身)，                                                                                                                                                                                       |
| Leader      | 每个 Replication 集合中的 Partition 都会选出一个唯一的 Leader，所有的读写请求都由 Leader 处理。其他 Replicas 从 Leader 处把数据更新同步到本地，                                                                                                                                                                                             |
| Broker      | Kafka 中使用 Broker 来接受 Producer 和 Consumer 的请求，并把 Message 持久化到本地磁盘。每个 Cluster 当中会选举出一个 Broker 来担任 Controller，负责处理 Partition 的 Leader 选举，协调 Partition 迁移等工作，                                                                                                                               |
| ISR         | In-Sync Replica,是 Replicas 的一个子集，表示目前 Alive 且与 Leader 能够“Catch-up”的 Replicas 集合。由于读写都是首先落到 Leader 上，所以一般来说通过同步机制从 Leader 上拉取数据的 Replica 都会和 Leader 有一些延迟(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该 Replica 踢出 ISR。每个 Leader Partition 都有它自己独立的 ISR |

设计思想

| Concepts           | Function                                                                                                                                                                                                                           |
| ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Consumergroup      | 各个 consumer 可以组成一个组，每个消息只能被组中的一个 consumer 消费，如果一个消息可以被多个 consumer 消费的话，那么这些 consumer 必须在不同的组，                                                                                 |
| 消息状态           | 在 Kafka 中，消息的状态被保存在 consumer 中，broker 不会关心哪个消息被消费了被谁消费了，只记录一个 offset 值(指向 partition 中下一个要被消费的消息位置)，这就意味着如果 consumer 处理不好的话，broker 上的一个消息可能会被消费多次 |
| 消息持久化         | Kafka 中会把消息持久化到本地文件系统中，并且保持极高的效率，                                                                                                                                                                       |
| 消息有效期         | Kafka 会长久保留其中的消息，以便 consumer 可以多次消费，当然其中很多细节是可配置的，                                                                                                                                               |
| 批量发送           | Kafka 支持以消息集合为单位进行批量发送，以提高 push 效率，                                                                                                                                                                         |
| push-and-pull      | Kafka 中的 Producer 和 consumer 采用的是 push-and-pull 模式，即 Producer 只管向 broker push 消息，consumer 只管从 broker pull 消息，两者对消息的生产和消费是异步的，                                                               |
| Broker 之间的关系  | 不是主从关系，各个 broker 在集群中地位一样，我们可以随意的增加或删除任何一个 broker 节点，                                                                                                                                         |
| 负载均衡           | Kafka 提供了一个 metadata API 来管理 broker 之间的负载(对 Kafka0.8.x 而言，对于 0.7.x 主要靠 zookeeper 来实现负载均衡)，                                                                                                           |
| 同步异步           | Producer 采用异步 push 方式，极大提高 Kafka 系统的吞吐率(可以通过参数控制是采用同步还是异步方式)，                                                                                                                                 |
| 分区机制 partition | Kafka 的 broker 端支持消息分区，Producer 可以决定把消息发到哪个分区，在一个分区中消息的顺序就是 Producer 发送消息的顺序，一个主题中可以有多个分区，具体分区的数量是可配置的。分区的意义很重大，后面的内容会逐渐体现，              |

# 特性与场景

## Use Cases | 使用场景

### Message Broker | 用于异构服务之间的消息传递

### Statistic Analysis | 统计分析

活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量(Page View)、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据(CPU、IO 使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。

近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。

### Stream Processing | 流处理

# TBD

- https://mp.weixin.qq.com/s/fX26tCdYSMgwM54_2CpVrw

Kafka 是一个高吞吐量、分布式的发布—订阅消息系统。据 Kafka 官方网站介绍，当前的 Kafka 已经定位为一个分布式流式处理平台(a distributed streaming platform)，它最初由 LinkedIn 公司开发，后来成为 Apache 项目的一部分。Kafka 核心模块使用 Scala 语言开发，支持多语言(如 Java、C/C++、Python、Go、Erlang、Node.js 等)客户端，它以可水平扩展和具有高吞吐量等特性而被广泛使用。

与 RabbitMQ 这样的传统消息中间件相比，Kafka 并不适合做 Task Queue。Kafka 将一组消息抽象归纳为一个主题(Topic)，每个主题又被分成一个或多个分区(Partition)。每个分区由一系列有序、不可变的消息组成，是一个有序队列；Kafka 只能保证一个分区之内消息的有序性，并不能保证跨分区消息的有序性。同一个分区的一条消息只能被同一个消费组下某一个消费者消费，但不同消费组的消费者可同时消费该消息。

Kafka Broker 本身并不会记录消息的消费情况，而是交由消费者通过偏移量记录，这样使其非常方便地实现了 "at-least-once" 处理模型；但是也意味着我们并不能随机地获取某校消息。

· 能够允许发布和订阅流数据。从这个角度来讲，平台更像一个消息队列或者企业级的消息系统。
· 存储流数据时提供相应的容错机制。
· 当流数据到达时能够被及时处理。

(1)具有高吞吐量来支持诸如实时的日志集这样的大规模事件流。
(2)能够很好地处理大量积压的数据，以便能够周期性地加载离线数据进行处理。
(3)能够低延迟地处理传统消息应用场景。
(4)能够支持分区、分布式，实时地处理消息，同时具有容错保障机制。

![image](https://user-images.githubusercontent.com/5803001/45597812-f00f4180-ba03-11e8-99f8-553d7eaf1b08.png)

# 消费模型

1．主题
Kafka 将一组消息抽象归纳为一个主题(Topic)，也就是说，一个主题就是对消息的一个分类。生产者将消息发送到特定主题，消费者订阅主题或主题的某些分区进行消费。

主题(Topic)是 Kafka 的核心概念，

2．消息
消息是 Kafka 通信的基本单位，由一个固定长度的消息头和一个可变长度的消息体构成。在老版本中，每一条消息称为 Message；在由 Java 重新实现的客户端中，每一条消息称为 Record。

3．分区和副本

Kafka 将一组消息归纳为一个主题，而每个主题又被分成一个或多个分区(Partition)。每个分区由一系列有序、不可变的消息组成，是一个有序队列。
每个分区在物理上对应为一个文件夹，分区的命名规则为主题名称后接“—”连接符，之后再接分区编号，分区编号从 0 开始，编号最大值为分区的总数减 1。每个分区又有一至多个副本(Replica)，分区的副本分布在集群的不同代理上，以提高可用性。从存储角度上分析，分区的每个副本在逻辑上抽象为一个日志(Log)对象，即分区的副本与日志对象是一一对应的。每个主题对应的分区数可以在 Kafka 启动时所加载的配置文件中配置，也可以在创建主题时指定。当然，客户端还可以在主题创建后修改主题的分区数。
分区使得 Kafka 在并发处理上变得更加容易，理论上来说，分区数越多吞吐量越高，但这要根据集群实际环境及业务场景而定。同时，分区也是 Kafka 保证消息被顺序消费以及对消息进行负载均衡的基础。

Kafka 只能保证一个分区之内消息的有序性，并不能保证跨分区消息的有序性。每条消息被追加到相应的分区中，是顺序写磁盘，因此效率非常高，这是 Kafka 高吞吐率的一个重要保证。同时与传统消息系统不同的是，Kafka 并不会立即删除已被消费的消息，由于磁盘的限制消息也不会一直被存储(事实上这也是没有必要的)，因此 Kafka 提供两种删除老数据的策略，一是基于消息已存储的时间长度，二是基于分区的大小。这两种策略都能通过配置文件进行配置。

Leader 副本和 Follower 副本
由于 Kafka 副本的存在，就需要保证一个分区的多个副本之间数据的一致性，Kafka 会选择该分区的一个副本作为 Leader 副本，而该分区其他副本即为 Follower 副本，只有 Leader 副本才负责处理客户端读/写请求，Follower 副本从 Leader 副本同步数据。如果没有 Leader 副本，那就需要所有的副本都同时负责读/写请求处理，同时还得保证这些副本之间数据的一致性，假设有 n 个副本则需要有 n×n 条通路来同步数据，这样数据的一致性和有序性就很难保证。
引入 Leader 副本后客户端只需与 Leader 副本进行交互，这样数据一致性及顺序性就有了保证。Follower 副本从 Leader 副本同步消息，对于 n 个副本只需 n−1 条通路即可，这样就使得系统更加简单而高效。副本 Follower 与 Leader 的角色并不是固定不变的，如果 Leader 失效，通过相应的选举算法将从其他 Follower 副本中选出新的 Leader 副本。

5．偏移量

任何发布到分区的消息会被直接追加到日志文件(分区目录下以“.log”为文件名后缀的数据文件)的尾部，而每条消息在日志文件中的位置都会对应一个按序递增的偏移量。偏移量是一个分区下严格有序的逻辑值，它并不表示消息在磁盘上的物理位置。由于 Kafka 几乎不允许对消息进行随机读写，因此 Kafka 并没有提供额外索引机制到存储偏移量，也就是说并不会给偏移量再提供索引。消费者可以通过控制消息偏移量来对消息进行消费，如消费者可以指定消费的起始偏移量。为了保证消息被顺序消费，消费者已消费的消息对应的偏移量也需要保存。需要说明的是，消费者对消息偏移量的操作并不会影响消息本身的偏移量。旧版消费者将消费偏移量保存到 ZooKeeper 当中，而新版消费者是将消费偏移量保存到 Kafka 内部一个主题当中。当然，消费者也可以自己在外部系统保存消费偏移量，而无需保存到 Kafka 中。

6．日志段

一个日志又被划分为多个日志段(LogSegment)，日志段是 Kafka 日志对象分片的最小单位。与日志对象一样，日志段也是一个逻辑概念，一个日志段对应磁盘上一个具体日志文件和两个索引文件。日志文件是以“.log”为文件名后缀的数据文件，用于保存消息实际数据。两个索引文件分别以“.index”和“.timeindex”作为文件名后缀，分别表示消息偏移量索引文件和消息时间戳索引文件。

7．代理

在 Kafka 基本体系结构中我们提到了 Kafka 集群。Kafka 集群就是由一个或多个 Kafka 实例构成，我们将每一个 Kafka 实例称为代理(Broker)，通常也称代理为 Kafka 服务器(KafkaServer)。在生产环境中 Kafka 集群一般包括一台或多台服务器，我们可以在一台服务器上配置一个或多个代理。每一个代理都有唯一的标识 id，这个 id 是一个非负整数。在一个 Kafka 集群中，每增加一个代理就需要为这个代理配置一个与该集群中其他代理不同的 id，id 值可以选择任意非负整数即可，只要保证它在整个 Kafka 集群中唯一，这个 id 就是代理的名字，也就是在启动代理时配置的 broker.id 对应的值，因此在本书中有时我们也称为 brokerId。由于给每个代理分配了不同的 brokerId，这样对代理进行迁移就变得更方便，从而对消费者来说是透明的，不会影响消费者对消息的消费。代理有很多个参数配置，由于在本节只是对其概念进行阐述，因此不做深入展开，对于代理相关配置将穿插在本书具体组件实现原理、流程分析及相关实战操作章节进行介绍。

8．生产者

生产者(Producer)负责将消息发送给代理，也就是向 Kafka 代理发送消息的客户端。

9．消费者和消费组
消费者(Comsumer)以拉取(pull)方式拉取数据，它是消费的客户端。在 Kafka 中每一个消费者都属于一个特定消费组(ConsumerGroup)，我们可以为每个消费者指定一个消费组，以 groupId 代表消费组名称，通过 group.id 配置设置。如果不指定消费组，则该消费者属于默认消费组 test-consumer-group。同时，每个消费者也有一个全局唯一的 id，通过配置项 client.id 指定，如果客户端没有指定消费者的 id，Kafka 会自动为该消费者生成一个全局唯一的 id，格式为 ${groupId}-${hostName}-${timestamp}-${UUID 前 8 位字符}。同一个主题的一条消息只能被同一个消费组下某一个消费者消费，但不同消费组的消费者可同时消费该消息。消费组是 Kafka 用来实现对一个主题消息进行广播和单播的手段，实现消息广播只需指定各消费者均属于不同的消费组，消息单播则只需让各消费者属于同一个消费组。

10．ISR
Kafka 在 ZooKeeper 中动态维护了一个 ISR(In-sync Replica)，即保存同步的副本列表，该列表中保存的是与 Leader 副本保持消息同步的所有副本对应的代理节点 id。如果一个 Follower 副本宕机(本书用宕机来特指某个代理失效的情景，包括但不限于代理被关闭，如代理被人为关闭或是发生物理故障、心跳检测过期、网络延迟、进程崩溃等)或是落后太多，则该 Follower 副本节点将从 ISR 列表中移除。

11．ZooKeeper

这里我们并不打算介绍 ZooKeeper 的相关知识，只是简要介绍 ZooKeeper 在 Kafka 中的作用。Kafka 利用 ZooKeeper 保存相应元数据信息，Kafka 元数据信息包括如代理节点信息、Kafka 集群信息、旧版消费者信息及其消费偏移量信息、主题信息、分区状态信息、分区副本分配方案信息、动态配置信息等。Kafka 在启动或运行过程当中会在 ZooKeeper 上创建相应节点来保存元数据信息，Kafka 通过监听机制在这些节点注册相应监听器来监听节点元数据的变化，从而由 ZooKeeper 负责管理维护 Kafka 集群，同时通过 ZooKeeper 我们能够很方便地对 Kafka 集群进行水平扩展及数据迁移。

Kafka 高度依赖于文件系统来存储和缓存消息。说到文件系统，大家普遍认为磁盘读写慢，依赖于文件系统进行存储和缓存消息势必在性能上会大打折扣，其实文件系统存储速度快慢一定程度上也取决于我们对磁盘的用法。据 Kafka 官方网站介绍：6 块 7200r/min SATA RAID-5 阵列的磁盘线性写的速度为 600 MB/s，而随机写的速度为 100KB/s，线性写的速度约是随机写的 6000 多倍。由此看来磁盘的快慢取决于我们是如何去应用磁盘。加之现代的操作系统提供了预读(read-ahead)和延迟写(write-behind)技术，使得磁盘的写速度并不是大家想象的那么慢。同时，由于 Kafka 是基于 JVM(Java Virtual Machine)的，而 Java 对象内存消耗非常高，且随着 Java 对象的增加 JVM 的垃圾回收也越来越频繁和繁琐，这些都加大了内存的消耗。鉴于以上因素，使用文件系统和依赖于页缓存(page cache)的存储比维护一个内存的存储或是应用其他结构来存储消息更有优势，因此 Kafka 选择以文件系统来存储数据。
消息系统数据持久化一般采用为每个消费者队列提供一个 B 树或其他通用的随机访问数据结构来维护消息的元数据，B 树操作的时间复杂度为 O(log n)，O(log n)的时间复杂度可以看成是一个常量时间，而且 B 树可以支持各种各样的事务性和非事务性语义消息的传递。尽管 B 树具有这些优点，但这并不适合磁盘操作。目前的磁盘寻道时间一般在 10ms 以内，对一块磁盘来说，在同一时刻只能有一个磁头来读写磁盘，这样在并发 IO 能力上就有问题。同时，对树结构性能的观察结果表明：其性能会随着数据的增长而线性下降。鉴于消息系统本身的作用考虑，数据的持久化队列可以建立在简单地对文件进行追加的实现方案上。因为是顺序追加，所以 Kafka 在设计上是采用时间复杂度 O(1)的磁盘结构，它提供了常量时间的性能，即使是存储海量的信息(TB 级)也如此，性能和数据的大小关系也不大，同时 Kafka 将数据持久化到磁盘上，这样只要磁盘空间足够大数据就可以一直追加，而不会像一般的消息系统在消息被消费后就删除掉，Kafka 提供了相关配置让用户自己决定消息要保存多久，这样为消费者提供了更灵活的处理方式，因此 Kafka 能够在没有性能损失的情况下提供一般消息系统不具备的特性。
正是由于 Kafka 将消息进行持久化，使得 Kafka 在机器重启后，已存储的消息可继续恢复使用。同时 Kafka 能够很好地支持在线或离线处理、与其他存储及流处理框架的集成。

2. 高吞吐量
   高吞吐量是 Kafka 设计的主要目标，Kafka 将数据写到磁盘，充分利用磁盘的顺序读写。同时，Kafka 在数据写入及数据同步采用了零拷贝(zero-copy)技术，采用 sendFile() 函数调用，sendFile() 函数是在两个文件描述符之间直接传递数据，完全在内核中操作，从而避免了内核缓冲区与用户缓冲区之间数据的拷贝，操作效率极高。Kafka 还支持数据压缩及批量发送，同时 Kafka 将每个主题划分为多个分区，这一系列的优化及实现方法使得 Kafka 具有很高的吞吐量。经大多数公司对 Kafka 应用的验证，Kafka 支持每秒数百万级别的消息。
3. 扩展性
   Kafka 要支持对大规模数据的处理，就必须能够对集群进行扩展，分布式必须是其特性之一，这样就可以将多台廉价的 PC 服务器搭建成一个大规模的消息系统。Kafka 依赖 ZooKeeper 来对集群进行协调管理，这样使得 Kafka 更加容易进行水平扩展，生产者、消费者和代理都为分布式，可配置多个。同时在机器扩展时无需将整个集群停机，集群能够自动感知，重新进行负责均衡及数据复制。

4. 安全机制
   当前版本的 Kafka 支持以下几种安全措施：
   · 通过 SSL 和 SASL(Kerberos)，SASL/PLAIN 验证机制支持生产者、消费者与代理连接时的身份认证；
   · 支持代理与 ZooKeeper 连接身份验证；
   · 通信时数据加密；
   · 客户端读、写权限认证；
   · Kafka 支持与外部其他认证授权服务的集成。

5. 数据备份
   Kafka 可以为每个主题指定副本数，对数据进行持久化备份，这可以一定程度上防止数据丢失，提高可用性。

6. 轻量级
   Kafka 的代理是无状态的，即代理不记录消息是否被消费，消费偏移量的管理交由消费者自己或组协调器来维护。同时集群本身几乎不需要生产者和消费者的状态信息，这就使得 Kafka 非常轻量级，同时生产者和消费者客户端实现也非常轻量级。

9．消息压缩
Kafka 支持 Gzip、Snappy、LZ4 这 3 种压缩方式，通常把多条消息放在一起组成 MessageSet，然后再把 MessageSet 放到一条消息里面去，从而提高压缩比率进而提高吞吐量。

消息系统或是说消息队列中间件是当前处理大数据一个非常重要的组件，用来解决应用解耦、异步通信、流量控制等问题，从而构建一个高效、灵活、消息同步和异步传输处理、存储转发、可伸缩和最终一致性的稳定系统。当前比较流行的消息中间件有 Kafka、RocketMQ、RabbitMQ、ZeroMQ、ActiveMQ、MetaMQ、Redis 等，这些消息中间件在性能及功能上各有所长。如何选择一个消息中间件取决于我们的业务场景、系统运行环境、开发及运维人员对消息中件间掌握的情况等。我认为在下面这些场景中，Kafka 是一个不错的选择。
(1)消息系统。Kafka 作为一款优秀的消息系统，具有高吞吐量、内置的分区、备份冗余分布式等特点，为大规模消息处理提供了一种很好的解决方案。
(2)应用监控。利用 Kafka 采集应用程序和服务器健康相关的指标，如 CPU 占用率、IO、内存、连接数、TPS、QPS 等，然后将指标信息进行处理，从而构建一个具有监控仪表盘、曲线图等可视化监控系统。例如，很多公司采用 Kafka 与 ELK(ElasticSearch、Logstash 和 Kibana)整合构建应用服务监控系统。
(3)网站用户行为追踪。为了更好地了解用户行为、操作习惯，改善用户体验，进而对产品升级改进，将用户操作轨迹、内容等信息发送到 Kafka 集群上，通过 Hadoop、Spark 或 Strom 等进行数据分析处理，生成相应的统计报告，为推荐系统推荐对象建模提供数据源，进而为每个用户进行个性化推荐。
(4)流处理。需要将已收集的流数据提供给其他流式计算框架进行处理，用 Kafka 收集流数据是一个不错的选择，而且当前版本的 Kafka 提供了 Kafka Streams 支持对流数据的处理。
(5)持久性日志。Kafka 可以为外部系统提供一种持久性日志的分布式系统。日志可以在多个节点间进行备份，Kafka 为故障节点数据恢复提供了一种重新同步的机制。同时，Kafka 很方便与 HDFS 和 Flume 进行整合，这样就方便将 Kafka 采集的数据持久化到其他外部系统

# 存储模型

Apache Kafka 和 Apache Pulsar 都有类似的消息概念。客户端通过主题与消息系统进行交互。每个主题都可以分为多个分区。然而，Apache Pulsar 和 Apache Kafka 之间的根本区别在于 Apache Kafka 是以分区为存储中心，而 Apache Pulsar 是以 Segment 为存储中心。

![image](https://user-images.githubusercontent.com/5803001/50600083-f3fb9c80-0eea-11e9-999d-b9e511f03edd.png)

在 Apache Kafka 中，分区只能存储在单个节点上并复制到其他节点，其容量受最小节点容量的限制。这意味着容量扩展需要对分区重新平衡，这反过来又需要重新复制整个分区，以平衡新添加的代理的数据和流量。

重新传输数据非常昂贵且容易出错，并且会消耗网络带宽和 IO。维护人员在执行此操作时必须非常小心，以避免破坏生产系统。

Kafka 中分区数据的重新拷贝不仅发生在以分区为中心的系统中的群集扩展上。许多其他事情也会触发数据重新拷贝，例如副本故障，磁盘故障或计算机的故障。在数据重新复制期间，分区通常不可用，直到数据重新复制完成。例如，如果您将分区配置为存储为 3 个副本，这时，如果丢失了一个副本，则必须重新复制完整个分区后，分区才可以再次可用。

在用户遇到故障之前，通常会忽略这种缺陷，因为许多情况下，在短时间内仅是对内存中缓存数据的读取。当数据被保存到磁盘后，用户将越来越多地不可避免地遇到数据丢失，故障恢复的问题，特别是在需要将数据长时间保存的场合。

相反，在 Apache Pulsar 中，同样是以分区为逻辑单元，但是以 Segment 为物理存储单元。分区随着时间的推移会进行分段，并在整个集群中均衡分布，旨在有效地迅速地扩展。

Pulsar 是以 Segment 为中心的，因此在扩展容量时不需要数据重新平衡和拷贝，旧数据不会被重新复制，这要归功于在 Apache BookKeeper 中使用可扩展的以 Segment 为中心的分布式日志存储系统。

通过利用分布式日志存储，Pulsar 可以最大化 Segment 放置选项，实现高写入和高读取可用性。例如，使用 BookKeeper，副本设置等于 2，只要任何 2 个 Bookie 启动，就可以对主题分区进行写入。对于读取可用性，只要主题分区的副本集中有 1 个处于活动状态，用户就可以读取它，而不会出现任何不一致。

总之，Apache Pulsar 这种独特的基于分布式日志存储的以 Segment 为中心的发布 / 订阅消息系统可以提供许多优势，例如可靠的流式系统，包括无限制的日志存储，无需分区重新平衡的即时扩展，快速复制修复以及通过最大化数据放置实现高写入和读取可用性选项。

# 消费者

# 存储模型

# 配置与实践

# TBD

- https://www.cnblogs.com/huxi2b/p/6223228.html
